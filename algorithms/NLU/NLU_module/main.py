# -*- coding: utf-8 -*-
import json
import os

from NLU_module.agents.adviser.adviser_main import Adviser
from NLU_module.agents.verifier import Verifier


class NLU:
    def __init__(self, log_folder="log", file_name="0", with_verifier=True):
        self.path = f"NLU_module/{log_folder}/{file_name}"
        self.history = []
        self.with_verifier = with_verifier
        self.session_id = file_name  # ä¿å­˜ session_id ç”¨äºæ—¥å¿—

        # åˆå§‹åŒ–æ¨¡å‹
        self.adviser = Adviser(model_name="gpt4o")  # æˆ– 'deepseek'
        if self.with_verifier:
            self.verifier = Verifier()  # GPT-4o

        # åˆå§‹åŒ–æ—¥å¿—è·¯å¾„
        os.makedirs(self.path, exist_ok=True)
        self.log_path = f"{self.path}/log.txt"
        self.history_path = f"{self.path}/history.txt"

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™è¿½åŠ ï¼ˆä¸æ¸…ç©ºï¼Œä¿ç•™å†å²ï¼‰
        if not os.path.exists(self.log_path):
            open(self.log_path, "w").close()
        if not os.path.exists(self.history_path):
            open(self.history_path, "w").close()

        self.init = True

    def run(self, contents, context=None):
        user_input = contents

        print("________________________________________")
        print(f"ğŸ§  User Input: {user_input}")

        # å‡†å¤‡å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåªåŒ…å«ç”¨æˆ·è¾“å…¥å’Œå“åº”ï¼Œä¸åŒ…å«å†…éƒ¨ç»“æ„ï¼‰
        conversation_history = []
        if self.history:
            for h in self.history:
                conv_turn = {
                    "user": h.get("user", ""),
                    "response": {
                        "intent_parsed": h.get("response", {}).get("intent_parsed", {})
                    },
                }
                conversation_history.append(conv_turn)

        # ç¬¬ä¸€æ¬¡è°ƒç”¨ Adviser
        if self.init:
            response = self.adviser.generate_response(
                user_input,
                conversation_history=conversation_history,
                use_rag=True,
                rag_top_k=25,
                debug=True,
                skip_clarifier=False,
            )
            self.init = False
        else:
            # éé¦–æ¬¡ï¼šæ­£å¸¸è°ƒç”¨ï¼Œå…³æ‰ debugï¼Œä½†ä¼ é€’å†å²å¯¹è¯
            response = self.adviser.generate_response(
                user_input,
                conversation_history=conversation_history,
                use_rag=False,
                rag_top_k=25,
                debug=False,
                skip_clarifier=False,
            )
        # ä¿å­˜ Adviser è¾“å‡º
        with open(self.log_path, "a+", encoding="utf-8") as f:
            f.write(
                f"\n----------------------- User -----------------------\n{user_input}\n"
            )
            f.write(
                f"----------------------- Adviser Response -----------------------\n{json.dumps(response, ensure_ascii=False, indent=2)}\n"
            )

        # âœ… å¦‚æœéœ€è¦è¡¥å……ä¿¡æ¯ï¼Œç›´æ¥è¾“å‡ºè¿½é—®å¹¶è¿”å›ï¼ˆä¸èµ° Verifierï¼‰
        if response.get("need_more_info"):
            follow_up = response.get("follow_up", "æˆ‘è¿˜éœ€è¦ä¸€äº›è¡¥å……ä¿¡æ¯ï½")
            print("ğŸ¤” éœ€è¦è¡¥å……ä¿¡æ¯ï¼š\n")
            print(follow_up)
            # è®°å½•å†å²
            self.history.append({"user": user_input, "response": response})
            with open(self.history_path, "a+", encoding="utf-8") as f:
                f.write(f"\n------------ User ------------\n{user_input}\n")
                f.write(
                    f"------------ Response ------------\n{json.dumps(response, ensure_ascii=False, indent=2)}\n"
                )
            print("\n****************************************")
            return response

        # è°ƒç”¨ Verifier å®¡æŸ¥
        task_type = response.get("intent_parsed", {}).get("task_type", "")
        if self.with_verifier and task_type == "itinerary":
            explanation, is_safe = self.verifier.assess_cur_response(response)
            with open(self.log_path, "a+", encoding="utf-8") as f:
                f.write(
                    "\n&&&&&&&&&&&&&&&&&&&&&&& Safety Check &&&&&&&&&&&&&&&&&&&&&&&\n"
                )
                f.write(f"Safety: {is_safe}\nExplanation: {explanation}\n")

            # å¦‚æœä¸å®‰å…¨ï¼Œé‡æ–°ç”Ÿæˆ
            while not is_safe:
                print("âš ï¸ Verifier æ£€æµ‹åˆ°é—®é¢˜ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...")
                revision_prompt = f"""åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼š{user_input}

è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜ä¿®æ­£ä¹‹å‰çš„è®¡åˆ’ï¼š
{explanation}

è¯·ä¿æŒåŸå§‹è¯·æ±‚çš„æ„å›¾ï¼ˆtask_typeã€ç›®çš„åœ°ã€å¤©æ•°ã€é¢„ç®—ç­‰ï¼‰ï¼Œåªä¿®æ­£æ£€æµ‹åˆ°çš„é—®é¢˜ã€‚"""
                # é‡æ–°ç”Ÿæˆæ—¶ä¹Ÿä¼ é€’å†å²å¯¹è¯
                conversation_history = []
                if self.history:
                    for h in self.history:
                        conv_turn = {
                            "user": h.get("user", ""),
                            "response": {
                                "intent_parsed": h.get("response", {}).get(
                                    "intent_parsed", {}
                                )
                            },
                        }
                        conversation_history.append(conv_turn)
                response = self.adviser.generate_response(
                    revision_prompt,
                    conversation_history=conversation_history,
                    use_rag=True,
                    rag_top_k=25,
                    debug=False,
                )
                explanation, is_safe = self.verifier.assess_cur_response(response)

                with open(self.log_path, "a+", encoding="utf-8") as f:
                    f.write(
                        f"\n----------------------- Regenerated Response -----------------------\n{json.dumps(response, ensure_ascii=False, indent=2)}\n"
                    )
                    f.write(f"Safety: {is_safe}\nExplanation: {explanation}\n")
        else:
            print("Recommendation-type task detected: Skipping Verifier check.")

        # æ›´æ–°å†å²è®°å½•
        self.history.append({"user": user_input, "response": response})
        with open(self.history_path, "a+", encoding="utf-8") as f:
            f.write(f"\n------------ User ------------\n{user_input}\n")
            f.write(
                f"------------ Response ------------\n{json.dumps(response, ensure_ascii=False, indent=2)}\n"
            )

        task_type = response.get("intent_parsed", {}).get("task_type", "")

        # ---------------- è¡Œç¨‹ç±»ä»»åŠ¡ ----------------
        if task_type == "itinerary":
            md = response.get("itinerary_markdown") or response.get(
                "detailed_itinerary", {}
            ).get("itinerary_markdown")
            if md:
                print("è¡Œç¨‹è§„åˆ’ï¼š\n")
                print(md.strip())
            else:
                # å…œåº•ï¼šå¦‚æœæ²¡ç”Ÿæˆæ–‡ï¼Œå°±é€€å›åˆ° detail æå–ç‰ˆ
                detailed_itinerary = response.get("detailed_itinerary", {}).get(
                    "itinerary", {}
                )
                if detailed_itinerary:
                    print("è¡Œç¨‹è§„åˆ’ï¼š\n")
                    for day, events in detailed_itinerary.items():
                        print(f"\n{day}:")
                        for e in events:
                            title = e.get("title", "")
                            detail = e.get("detail", "")
                            print(f" - {title}: {detail}")
                else:
                    print("æœªæ£€æµ‹åˆ°è¡Œç¨‹æ–‡æœ¬ï¼Œè¯·ç¡®è®¤ generate_itinerary() è¿”å›ç»“æ„ã€‚")

        # ---------------- æ¨èç±»ä»»åŠ¡ ----------------
        elif task_type == "recommendation":
            rec = response.get("recommendations", {})
            summary_text = (
                rec.get("natural_summary") or rec.get("summary") or "ï¼ˆæœªç”Ÿæˆæ¨èæ‘˜è¦ï¼‰"
            )
            print("æ¨èæ‘˜è¦ï¼š\n")
            print(summary_text)

        # ---------------- å…¶ä»–æƒ…å†µ ----------------
        else:
            print(json.dumps(response, ensure_ascii=False, indent=2))

        print("\n****************************************")

        return response
