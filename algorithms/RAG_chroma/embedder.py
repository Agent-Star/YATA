from __future__ import annotations

from typing import List

import numpy as np
from config import settings
from sentence_transformers import CrossEncoder, SentenceTransformer

_model: SentenceTransformer | None = None
_reranker: CrossEncoder | None = None


def _get_model() -> SentenceTransformer:
    global _model
    if _model is None:
        print(f"æ­£åœ¨åŠ è½½ embedding æ¨¡å‹: {settings.model_name}...")
        print("(é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…)")
        _model = SentenceTransformer(settings.model_name)
        # æ˜¾ç¤ºæ¨¡å‹ç¼“å­˜è·¯å¾„
        import os

        cache_dir = os.getenv("HF_HOME") or os.path.expanduser("~/.cache/huggingface")
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
        hub_path = os.path.join(cache_dir, "hub")
        print(f"æ¨¡å‹ç¼“å­˜ä½ç½®: {hub_path}")
    return _model


def embed_texts(texts: List[str]) -> np.ndarray:
    model = _get_model()
    embeddings = model.encode(
        texts,
        batch_size=settings.batch_size,
        show_progress_bar=False,
        convert_to_numpy=True,
        normalize_embeddings=settings.normalize_embeddings,
    )
    # Ensure float32 for pgvector
    return embeddings.astype(np.float32)


def get_embedding_dimension() -> int:
    """è¿”å›å½“å‰ embedding æ¨¡å‹çš„å‘é‡ç»´åº¦"""
    # BGE-M3 å›ºå®šä¸º 1024 ç»´
    if "bge-m3" in settings.model_name.lower():
        return 1024

    try:
        model = _get_model()
        if hasattr(model, "get_sentence_embedding_dimension") and (
            dim := model.get_sentence_embedding_dimension()
        ):
            return int(dim)
        # å…œåº•ï¼šç”¨å•æ¡æ–‡æœ¬ç¼–ç æ¨æ–­ç»´åº¦
        dim = int(embed_texts(["test"]).shape[1])
        return dim
    except Exception:
        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œæ ¹æ®æ¨¡å‹åç§°è¿”å›é»˜è®¤ç»´åº¦
        if "bge-m3" in settings.model_name.lower():
            return 1024
        elif "bge-base" in settings.model_name.lower():
            return 768
        elif "bge-small" in settings.model_name.lower():
            return 384
        else:
            return 384  # é»˜è®¤


def _get_reranker() -> CrossEncoder:
    global _reranker
    if _reranker is None:
        print("æ­£åœ¨åŠ è½½é‡æ’åºæ¨¡å‹...")
        print("(é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…)")
        _reranker = CrossEncoder(settings.rerank_model_name)
        print("é‡æ’åºæ¨¡å‹åŠ è½½å®Œæˆï¼")
    return _reranker


def rerank(query: str, documents: List[str]) -> List[float]:
    """ä½¿ç”¨äº¤å‰ç¼–ç å™¨å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº"""
    if not documents:
        return []
    reranker = _get_reranker()
    pairs = [[query, doc] for doc in documents]
    scores = reranker.predict(pairs, show_progress_bar=False)
    return scores.tolist() if hasattr(scores, "tolist") else list(scores)


def warmup_models() -> None:
    """é¢„åŠ è½½æ¨¡å‹ (åœ¨æœåŠ¡å¯åŠ¨æ—¶è°ƒç”¨, é¿å…é¦–æ¬¡è¯·æ±‚è¶…æ—¶)"""
    print("ğŸ”„ å¼€å§‹é¢„åŠ è½½ embedding æ¨¡å‹...")
    _ = _get_model()
    print("âœ… Embedding æ¨¡å‹é¢„åŠ è½½å®Œæˆ")

    # å¦‚æœå¯ç”¨äº†é‡æ’åº, ä¹Ÿé¢„åŠ è½½é‡æ’åºæ¨¡å‹
    if settings.use_reranking:
        print("ğŸ”„ å¼€å§‹é¢„åŠ è½½é‡æ’åºæ¨¡å‹...")
        _ = _get_reranker()
        print("âœ… é‡æ’åºæ¨¡å‹é¢„åŠ è½½å®Œæˆ")
    else:
        print("â„¹ï¸  é‡æ’åºæœªå¯ç”¨, è·³è¿‡é‡æ’åºæ¨¡å‹é¢„åŠ è½½")
